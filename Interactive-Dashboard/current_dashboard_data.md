|    | task   | model               | language          | metric   |   value |
|---:|:-------|:--------------------|:------------------|:---------|--------:|
|  0 | PIQA   | DeepSeek-R1-Distill | Macedonian        | accuracy |    0.57 |
|  1 | PIQA   | DeepSeek-R1-Distill | English           | accuracy |    0.63 |
|  2 | PIQA   | DeepSeek-R1-Distill | Chakavian Dialect | accuracy |    0.5  |
List of unique models in the results:

['DeepSeek-R1-Distill', 'Gemma 3', 'LLaMA 3.3', 'Qwen 3', 'GPT-3.5-Turbo', 'GPT-4o', 'GPT-5', 'Mistral Medium 3.1', 'Gemini 2.5 Flash', 'Claude Haiku 4.5', 'Gemini 2.5 Pro', 'GaMS-27B-Instruct', 'Gemini 3 Flash Preview', 'X-GENRE classifier', 'GPT-5-Nano', 'GPT-5-mini', 'GPT-4o-mini', 'IPTC XLM-R classifier', 'LLaMA 4 Scout', 'ParlaCAP-classifier', 'Mistral Small 3.2', 'XLM-R-ParlaSent']

List of tasks:

['PIQA', 'COPA', 'Genre', 'News Topic', 'Parliamentary Speech Topic', 'Sentiment']
