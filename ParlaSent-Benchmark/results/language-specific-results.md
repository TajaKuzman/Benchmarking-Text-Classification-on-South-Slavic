
#### en

| Model                  | Test Dataset      | Language   |   Macro F1 |   Micro F1 |
|:-----------------------|:------------------|:-----------|-----------:|-----------:|
| gpt-5                  | ParlaSent-EN-test | en         |      0.784 |      0.782 |
| gpt-5-mini-2025-08-07  | ParlaSent-EN-test | en         |      0.773 |      0.771 |
| gpt-4o-2024-08-06      | ParlaSent-EN-test | en         |      0.771 |      0.773 |
| gemma3:27b             | ParlaSent-EN-test | en         |      0.768 |      0.766 |
| gpt-5-nano-2025-08-07  | ParlaSent-EN-test | en         |      0.752 |      0.749 |
| llama3.3:latest        | ParlaSent-EN-test | en         |      0.749 |      0.745 |
| qwen3:32b              | ParlaSent-EN-test | en         |      0.744 |      0.743 |
| gpt-4o-mini-2024-07-18 | ParlaSent-EN-test | en         |      0.733 |      0.733 |
| XLM-R-ParlaSent        | ParlaSent-EN-test | en         |      0.728 |      0.727 |
| llama4:scout           | ParlaSent-EN-test | en         |      0.705 |      0.702 |
| gpt-3.5-turbo-0125     | ParlaSent-EN-test | en         |      0.7   |      0.698 |
| deepseek-r1:14b        | ParlaSent-EN-test | en         |      0.617 |      0.617 |
| SVC                    | ParlaSent-EN-test | en         |      0.346 |      0.395 |
| dummy-stratified       | ParlaSent-EN-test | en         |      0.327 |      0.346 |
| COMPLEMENTNB           | ParlaSent-EN-test | en         |      0.262 |      0.328 |
| dummy-most_frequent    | ParlaSent-EN-test | en         |      0.163 |      0.323 |

------------------------------------------

#### hr

| Model                  | Test Dataset       | Language   |   Macro F1 |   Micro F1 |
|:-----------------------|:-------------------|:-----------|-----------:|-----------:|
| gpt-4o-2024-08-06      | ParlaSent-BCS-test | hr         |      0.757 |      0.782 |
| gpt-5                  | ParlaSent-BCS-test | hr         |      0.756 |      0.773 |
| gpt-5-mini-2025-08-07  | ParlaSent-BCS-test | hr         |      0.752 |      0.762 |
| gemma3:27b             | ParlaSent-BCS-test | hr         |      0.728 |      0.742 |
| llama3.3:latest        | ParlaSent-BCS-test | hr         |      0.728 |      0.743 |
| gpt-5-nano-2025-08-07  | ParlaSent-BCS-test | hr         |      0.71  |      0.72  |
| qwen3:32b              | ParlaSent-BCS-test | hr         |      0.704 |      0.728 |
| XLM-R-ParlaSent        | ParlaSent-BCS-test | hr         |      0.698 |      0.719 |
| gpt-4o-mini-2024-07-18 | ParlaSent-BCS-test | hr         |      0.686 |      0.719 |
| llama4:scout           | ParlaSent-BCS-test | hr         |      0.668 |      0.679 |
| gpt-3.5-turbo-0125     | ParlaSent-BCS-test | hr         |      0.652 |      0.673 |
| deepseek-r1:14b        | ParlaSent-BCS-test | hr         |      0.595 |      0.613 |
| COMPLEMENTNB           | ParlaSent-BCS-test | hr         |      0.432 |      0.452 |
| SVC                    | ParlaSent-BCS-test | hr         |      0.345 |      0.496 |
| dummy-stratified       | ParlaSent-BCS-test | hr         |      0.316 |      0.365 |
| dummy-most_frequent    | ParlaSent-BCS-test | hr         |      0.197 |      0.419 |

------------------------------------------

#### bs

| Model                  | Test Dataset       | Language   |   Macro F1 |   Micro F1 |
|:-----------------------|:-------------------|:-----------|-----------:|-----------:|
| gpt-5                  | ParlaSent-BCS-test | bs         |      0.759 |      0.779 |
| gpt-5-mini-2025-08-07  | ParlaSent-BCS-test | bs         |      0.734 |      0.753 |
| gemma3:27b             | ParlaSent-BCS-test | bs         |      0.718 |      0.742 |
| gpt-4o-2024-08-06      | ParlaSent-BCS-test | bs         |      0.701 |      0.747 |
| XLM-R-ParlaSent        | ParlaSent-BCS-test | bs         |      0.697 |      0.721 |
| gpt-5-nano-2025-08-07  | ParlaSent-BCS-test | bs         |      0.684 |      0.695 |
| llama3.3:latest        | ParlaSent-BCS-test | bs         |      0.673 |      0.711 |
| llama4:scout           | ParlaSent-BCS-test | bs         |      0.628 |      0.658 |
| qwen3:32b              | ParlaSent-BCS-test | bs         |      0.614 |      0.658 |
| gpt-4o-mini-2024-07-18 | ParlaSent-BCS-test | bs         |      0.593 |      0.653 |
| gpt-3.5-turbo-0125     | ParlaSent-BCS-test | bs         |      0.584 |      0.626 |
| deepseek-r1:14b        | ParlaSent-BCS-test | bs         |      0.568 |      0.589 |
| COMPLEMENTNB           | ParlaSent-BCS-test | bs         |      0.447 |      0.495 |
| SVC                    | ParlaSent-BCS-test | bs         |      0.345 |      0.532 |
| dummy-stratified       | ParlaSent-BCS-test | bs         |      0.32  |      0.363 |
| dummy-most_frequent    | ParlaSent-BCS-test | bs         |      0.216 |      0.479 |

------------------------------------------

#### sr

| Model                  | Test Dataset       | Language   |   Macro F1 |   Micro F1 |
|:-----------------------|:-------------------|:-----------|-----------:|-----------:|
| gpt-5                  | ParlaSent-BCS-test | sr         |      0.768 |      0.783 |
| gpt-5-mini-2025-08-07  | ParlaSent-BCS-test | sr         |      0.761 |      0.774 |
| gpt-4o-2024-08-06      | ParlaSent-BCS-test | sr         |      0.738 |      0.764 |
| gpt-5-nano-2025-08-07  | ParlaSent-BCS-test | sr         |      0.72  |      0.727 |
| XLM-R-ParlaSent        | ParlaSent-BCS-test | sr         |      0.71  |      0.732 |
| gemma3:27b             | ParlaSent-BCS-test | sr         |      0.707 |      0.725 |
| qwen3:32b              | ParlaSent-BCS-test | sr         |      0.707 |      0.723 |
| llama3.3:latest        | ParlaSent-BCS-test | sr         |      0.693 |      0.711 |
| gpt-4o-mini-2024-07-18 | ParlaSent-BCS-test | sr         |      0.681 |      0.706 |
| gpt-3.5-turbo-0125     | ParlaSent-BCS-test | sr         |      0.664 |      0.67  |
| llama4:scout           | ParlaSent-BCS-test | sr         |      0.651 |      0.669 |
| deepseek-r1:14b        | ParlaSent-BCS-test | sr         |      0.597 |      0.615 |
| COMPLEMENTNB           | ParlaSent-BCS-test | sr         |      0.442 |      0.477 |
| SVC                    | ParlaSent-BCS-test | sr         |      0.37  |      0.535 |
| dummy-stratified       | ParlaSent-BCS-test | sr         |      0.327 |      0.361 |
| dummy-most_frequent    | ParlaSent-BCS-test | sr         |      0.211 |      0.462 |

------------------------------------------
