{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "from time import sleep\n",
    "import time\n",
    "from openai import OpenAI\n",
    "from tqdm import tqdm\n",
    "client = OpenAI(api_key=open('API_key').read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(272, 4) (790, 6)\n"
     ]
    }
   ],
   "source": [
    "# Load the test datasets from the GitHub repositories (access to them is obtained by request to the AGILE repository owner)\n",
    "\n",
    "en_ginco = pd.read_json(\"../../datasets/EN-GINCO-test-dataset/EN-GINCO.jsonl\", lines=True)\n",
    "x_ginco = pd.read_json(\"../../datasets/X-GINCO-test-set/X-GINCO.jsonl\", lines=True)\n",
    "\n",
    "print(en_ginco.shape, x_ginco.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "      <th>dataset</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Welcome to KBismarck.org! This is a community ...</td>\n",
       "      <td>Information/Explanation</td>\n",
       "      <td>EN-GINCO</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Why graft thrives in postconflict zones &lt;p&gt; A ...</td>\n",
       "      <td>News</td>\n",
       "      <td>EN-GINCO</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text                   labels  \\\n",
       "0  Welcome to KBismarck.org! This is a community ...  Information/Explanation   \n",
       "1  Why graft thrives in postconflict zones <p> A ...                     News   \n",
       "\n",
       "    dataset language  \n",
       "0  EN-GINCO  English  \n",
       "1  EN-GINCO  English  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_ginco.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_gpt(df_test_name, gpt_model):\n",
    "\n",
    "\tdfs = {\n",
    "\t\t\"en-ginco\": en_ginco,\n",
    "\t\t\"x-ginco\": x_ginco\n",
    "\t}\n",
    "\n",
    "\tdf = dfs[df_test_name]\n",
    "\n",
    "\tresponses = []\n",
    "\t\n",
    "\ttexts = df[\"text\"].to_list()\n",
    "\n",
    "\tstart_time = time.time()\n",
    "\n",
    "\tlabels_dict = {\n",
    "\t\t0: \"Other\",\n",
    "\t\t1: \"Information/Explanation\",\n",
    "\t\t2: \"News\",\n",
    "\t\t3: \"Instruction\",\n",
    "\t\t4: \"Opinion/Argumentation\",\n",
    "\t\t5: \"Forum\",\n",
    "\t\t6: \"Prose/Lyrical\",\n",
    "\t\t7: \"Legal\",\n",
    "\t\t8: \"Promotion\"\n",
    "\t}\n",
    "\n",
    "\tfor text in texts:\n",
    "\t\t# the \"v5\" models do not have the \"temperature\" parameter\n",
    "\t\tif \"gpt-5\" not in gpt_model:\n",
    "\t\t\tcompletion = client.chat.completions.create(model=gpt_model,\n",
    "\t\t\tresponse_format= {\"type\": \"json_object\"},\n",
    "\t\t\tmessages= [\n",
    "\t\t\t{\n",
    "\t\t\t\t\"role\": \"user\",\n",
    "\t\t\t\t\"content\": f\"\"\"\n",
    "\t\t\t\t### Task\n",
    "\t\t\t\tYour task is to classify the following text according to genre. Genres are text types, defined by the function of the text, author’s purpose and form of the text. Always provide a label, even if you are not sure.\n",
    "\n",
    "\t\t\t\t### Output format\n",
    "\t\t\t\t\tReturn a valid JSON dictionary with the following key: 'genre' and a value should be an integer which represents one of the labels according to the following dictionary: {labels_dict}.\n",
    "\n",
    "\t\t\t\t\t\n",
    "\t\t\t\t\tText: '{text}'\n",
    "\t\t\t\"\"\"\n",
    "\t\t\t\t}\n",
    "\t\t\t],\n",
    "\t\t\ttemperature = 0)\n",
    "\t\t# the \"v5\" models do not have the \"temperature\" parameter\n",
    "\t\telif \"gpt-5\" in gpt_model:\n",
    "\t\t\tcompletion = client.chat.completions.create(model=gpt_model,\n",
    "\t\t\tresponse_format= {\"type\": \"json_object\"},\n",
    "\t\t\tmessages= [\n",
    "\t\t\t{\n",
    "\t\t\t\t\"role\": \"user\",\n",
    "\t\t\t\t\"content\": f\"\"\"\n",
    "\t\t\t\t### Task\n",
    "\t\t\t\tYour task is to classify the following text according to genre. Genres are text types, defined by the function of the text, author’s purpose and form of the text. Always provide a label, even if you are not sure.\n",
    "\n",
    "\t\t\t\t### Output format\n",
    "\t\t\t\t\tReturn a valid JSON dictionary with the following key: 'genre' and a value should be an integer which represents one of the labels according to the following dictionary: {labels_dict}.\n",
    "\n",
    "\t\t\t\t\t\n",
    "\t\t\t\t\tText: '{text}'\n",
    "\t\t\t\"\"\"\n",
    "\t\t\t\t}\n",
    "\t\t\t],\n",
    "\t\t)\n",
    "\t\telse:\n",
    "\t\t\tprint(\"The model is not supported, check the code.\")\n",
    "\n",
    "\t\tresponse=completion.choices[0].message.content\n",
    "\n",
    "\t\tresponse = response.replace(\"\\n\", \"\")\n",
    "\t\tresponse = response.replace(\"\\t\", \"\")\n",
    "\n",
    "\t\t# Convert the string into a dictionary\n",
    "\t\tresponse = json.loads(response)\n",
    "\n",
    "\t\t# Get out a label\n",
    "\t\ttry:\n",
    "\t\t\tpredicted = labels_dict[response[\"genre\"]]\n",
    "\t\t\tresponses.append(predicted)\n",
    "\t\t# add a possibility of something going wrong\n",
    "\t\texcept:\n",
    "\t\t\tpredicted = \"error\"\n",
    "\t\t\tprint(\"error with extracting a label\")\n",
    "\t\t\tresponses.append(predicted)\n",
    "\n",
    "\tend_time = time.time()\n",
    "\telapsed_time_min = end_time-start_time\n",
    "\n",
    "\tprint(f\"Prediction finished. It took {elapsed_time_min/60} min for {df.shape[0]} instances - {elapsed_time_min/df.shape[0]} s per instance.\")\n",
    "\n",
    "\t# Create a json with results\n",
    "\n",
    "\tcurrent_results = {\n",
    "\t\t\"system\": gpt_model,\n",
    "\t\t\"predictions\": [\n",
    "\t\t\t{\n",
    "\t\t\t\"train\": \"X-GENRE (train split)\",\n",
    "\t\t\t\"test\": \"{}\".format(df_test_name),\n",
    "\t\t\t\"predictions\": responses,\n",
    "\t\t\t}\n",
    "\t\t]\n",
    "\t\t}\n",
    "\n",
    "\t# Save the results as a new json\n",
    "\twith open(\"submissions/submission-{}-{}.json\".format(gpt_model, df_test_name), \"w\") as file:\n",
    "\t\tjson.dump(current_results, file)\n",
    "\n",
    "\tprint(\"Classification with {} on {} finished.\".format(gpt_model, df_test_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for test in [\"en-ginco\", \"x-ginco\"]:\n",
    "\tfor model in [\"gpt-4o-2024-08-06\", \"gpt-3.5-turbo-0125\", \"gpt-4o-mini-2024-07-18\"]:\n",
    "\t\tprint(model)\n",
    "\t\tpredict_gpt(test, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpt-5-nano-2025-08-07\n",
      "Prediction finished. It took 11.63731210231781 min for 272 instances - 2.567054140217164 s per instance.\n",
      "Classification with gpt-5-nano-2025-08-07 on en-ginco finished.\n",
      "gpt-5-mini-2025-08-07\n",
      "Prediction finished. It took 10.601998893419902 min for 272 instances - 2.3386762264896843 s per instance.\n",
      "Classification with gpt-5-mini-2025-08-07 on en-ginco finished.\n",
      "gpt-5\n",
      "Prediction finished. It took 20.794515120983124 min for 272 instances - 4.587025394334512 s per instance.\n",
      "Classification with gpt-5 on en-ginco finished.\n",
      "gpt-5-nano-2025-08-07\n",
      "Prediction finished. It took 35.32288513183594 min for 790 instances - 2.682750769506527 s per instance.\n",
      "Classification with gpt-5-nano-2025-08-07 on x-ginco finished.\n",
      "gpt-5-mini-2025-08-07\n",
      "Prediction finished. It took 36.89934118191401 min for 790 instances - 2.802481608752963 s per instance.\n",
      "Classification with gpt-5-mini-2025-08-07 on x-ginco finished.\n",
      "gpt-5\n",
      "Prediction finished. It took 53.55667865673701 min for 790 instances - 4.067595847347115 s per instance.\n",
      "Classification with gpt-5 on x-ginco finished.\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the new v5 models\n",
    "for test in [\"en-ginco\", \"x-ginco\"]:\n",
    "\tfor model in [\"gpt-5-nano-2025-08-07\", \"gpt-5-mini-2025-08-07\",\"gpt-5\"]:\n",
    "\t\tprint(model)\n",
    "\t\tpredict_gpt(test, model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "emma_main",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
