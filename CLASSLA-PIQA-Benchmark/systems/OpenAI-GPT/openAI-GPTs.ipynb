{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "from time import sleep\n",
    "import time\n",
    "from openai import OpenAI\n",
    "from tqdm import tqdm\n",
    "client = OpenAI(api_key=open('API_key').read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tests = ['piqa-en', 'piqa-mk', 'piqa-bg', 'piqa-sl', 'piqa-sr_cyrl', 'piqa-hr', 'piqa-sr_latn', 'piqa-bs', 'piqa-sl-cer', 'piqa-hr-ckm']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_gpt(df_test_name, gpt_model):\n",
    "\n",
    "\tdf_path = f\"../../datasets/{df_test_name}.jsonl\"\n",
    "\n",
    "\tresponses = []\n",
    "\tinstance_number = 0\n",
    "\n",
    "\tstart_time = time.time()\n",
    "\tfor line in open(df_path):\n",
    "\t\tinstance_number += 1\n",
    "\t\tentry=json.loads(line)\n",
    "\n",
    "\t\tprompt= f\"\"\"\n",
    "\t\t### Task\n",
    "\t\t\tGiven the following situation, which option is more likely to be correct?\n",
    "\n",
    "\t\t\tSituation: {entry['prompt']}\n",
    "\n",
    "\t\t\tOption 0: {entry['solution0']}\n",
    "\n",
    "\t\t\tOption 1: {entry['solution1']}\n",
    "\t\t\t\t\n",
    "\t\t### Output format\n",
    "\t\t\tReturn a valid JSON dictionary with the following key: 'answer' and a value should be either 0 (if option 0 is more plausible) or 1 (if option 1 is more plausible).\n",
    "\t\t\"\"\"\n",
    "\t\t\n",
    "\t\tif \"gpt-5\" not in gpt_model:\n",
    "\t\t\tcompletion = client.chat.completions.create(model=gpt_model,\n",
    "\t\t\t\tresponse_format= {\"type\": \"json_object\"},\n",
    "\t\t\t\tmessages=[\n",
    "\t\t\t\t{\n",
    "\t\t\t\t\t\"role\": \"user\",\n",
    "\t\t\t\t\t\"content\": prompt}\n",
    "\t\t\t\t],\n",
    "\t\t\t\ttemperature = 0\n",
    "\t\t\t\t)\n",
    "\t\t# the \"v5\" models do not have the \"temperature\" parameter\n",
    "\t\telif \"gpt-5\" in gpt_model:\n",
    "\t\t\tcompletion = client.chat.completions.create(model=gpt_model,\n",
    "\t\t\t\tresponse_format= {\"type\": \"json_object\"},\n",
    "\t\t\t\tmessages=[\n",
    "\t\t\t\t{\n",
    "\t\t\t\t\t\"role\": \"user\",\n",
    "\t\t\t\t\t\"content\": prompt}\n",
    "\t\t\t\t],\n",
    "\t\t\t\t#temperature = 0\n",
    "\t\t\t\t)\n",
    "\n",
    "\t\tinitial_response=completion.choices[0].message.content\n",
    "\t\t\n",
    "\t\tresponse = initial_response.replace(\"\\n\", \"\")\n",
    "\t\tresponse = response.replace(\"\\t\", \"\")\n",
    "\n",
    "\t\t# Get out a label\n",
    "\t\ttry:\n",
    "\t\t\t# Convert the string into a dictionary\n",
    "\t\t\tresponse = json.loads(response)\n",
    "\t\t\tpredicted = response[\"answer\"]\n",
    "\t\t\tresponses.append(predicted)\n",
    "\t\t# add a possibility of something going wrong\n",
    "\t\texcept:\n",
    "\t\t\tpredicted = initial_response\n",
    "\t\t\tprint(\"error with extracting a label:\")\n",
    "\t\t\tprint(initial_response)\n",
    "\t\t\tresponses.append(initial_response)\n",
    "\n",
    "\tend_time = time.time()\n",
    "\telapsed_time_min = end_time-start_time\n",
    "\n",
    "\tprint(f\"Prediction finished. It took {elapsed_time_min/60} min for {instance_number} instances - {elapsed_time_min/instance_number} s per instance.\")\n",
    "\n",
    "\t# Create a json with results\n",
    "\n",
    "\tcurrent_results = {\n",
    "\t\t\"system\": gpt_model,\n",
    "\t\t\"predictions\": [\n",
    "\t\t\t{\n",
    "\t\t\t\"train\": \"NA (zero-shot)\",\n",
    "\t\t\t\"test\": \"{}\".format(df_test_name),\n",
    "\t\t\t\"predictions\": responses,\n",
    "\t\t\t},\n",
    "\t\t]\n",
    "\t\t}\n",
    "\n",
    "\t# Save the results as a new json\n",
    "\twith open(\"submissions/submission-{}-{}.json\".format(gpt_model, df_test_name), \"w\") as file:\n",
    "\t\tjson.dump(current_results, file)\n",
    "\n",
    "\tprint(\"Classification with {} on {} finished.\".format(gpt_model, df_test_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tests = ['piqa-en', 'piqa-mk', 'piqa-bg', 'piqa-sl', 'piqa-sr_cyrl', 'piqa-hr', 'piqa-sr_latn', 'piqa-bs', 'piqa-sl-cer', 'piqa-hr-ckm']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpt-4o-2024-08-06\n",
      "Prediction finished. It took 1.332702386379242 min for 100 instances - 0.7996214318275452 s per instance.\n",
      "Classification with gpt-4o-2024-08-06 on piqa-en finished.\n",
      "gpt-3.5-turbo-0125\n",
      "Prediction finished. It took 1.1147172888120016 min for 100 instances - 0.668830373287201 s per instance.\n",
      "Classification with gpt-3.5-turbo-0125 on piqa-en finished.\n",
      "gpt-5-2025-08-07\n",
      "Prediction finished. It took 8.298507142066956 min for 100 instances - 4.979104285240173 s per instance.\n",
      "Classification with gpt-5-2025-08-07 on piqa-en finished.\n"
     ]
    }
   ],
   "source": [
    "# First, check that everything works well by evaluating the models on English\n",
    "for model in [\"gpt-4o-2024-08-06\", \"gpt-3.5-turbo-0125\", \"gpt-5-2025-08-07\"]:\n",
    "\tprint(model)\n",
    "\tpredict_gpt(\"piqa-en\", model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "piqa-mk\n",
      "gpt-4o-2024-08-06\n",
      "Prediction finished. It took 1.2247767806053163 min for 100 instances - 0.7348660683631897 s per instance.\n",
      "Classification with gpt-4o-2024-08-06 on piqa-mk finished.\n",
      "gpt-3.5-turbo-0125\n",
      "Prediction finished. It took 0.9944889426231385 min for 100 instances - 0.5966933655738831 s per instance.\n",
      "Classification with gpt-3.5-turbo-0125 on piqa-mk finished.\n",
      "piqa-bg\n",
      "gpt-4o-2024-08-06\n",
      "Prediction finished. It took 1.3237185835838319 min for 100 instances - 0.7942311501502991 s per instance.\n",
      "Classification with gpt-4o-2024-08-06 on piqa-bg finished.\n",
      "gpt-3.5-turbo-0125\n",
      "Prediction finished. It took 1.0784034331639607 min for 100 instances - 0.6470420598983765 s per instance.\n",
      "Classification with gpt-3.5-turbo-0125 on piqa-bg finished.\n",
      "piqa-sl\n",
      "gpt-4o-2024-08-06\n",
      "Prediction finished. It took 1.3038632035255433 min for 100 instances - 0.7823179221153259 s per instance.\n",
      "Classification with gpt-4o-2024-08-06 on piqa-sl finished.\n",
      "gpt-3.5-turbo-0125\n",
      "Prediction finished. It took 1.1057557463645935 min for 100 instances - 0.6634534478187561 s per instance.\n",
      "Classification with gpt-3.5-turbo-0125 on piqa-sl finished.\n",
      "piqa-sr_cyrl\n",
      "gpt-4o-2024-08-06\n",
      "Prediction finished. It took 1.1681818644205728 min for 100 instances - 0.7009091186523437 s per instance.\n",
      "Classification with gpt-4o-2024-08-06 on piqa-sr_cyrl finished.\n",
      "gpt-3.5-turbo-0125\n",
      "Prediction finished. It took 1.0276518901189169 min for 100 instances - 0.6165911340713501 s per instance.\n",
      "Classification with gpt-3.5-turbo-0125 on piqa-sr_cyrl finished.\n",
      "piqa-hr\n",
      "gpt-4o-2024-08-06\n",
      "Prediction finished. It took 1.166743568579356 min for 100 instances - 0.7000461411476135 s per instance.\n",
      "Classification with gpt-4o-2024-08-06 on piqa-hr finished.\n",
      "gpt-3.5-turbo-0125\n",
      "Prediction finished. It took 1.3781456232070923 min for 100 instances - 0.8268873739242554 s per instance.\n",
      "Classification with gpt-3.5-turbo-0125 on piqa-hr finished.\n",
      "piqa-sr_latn\n",
      "gpt-4o-2024-08-06\n",
      "Prediction finished. It took 1.2041863600413005 min for 100 instances - 0.7225118160247803 s per instance.\n",
      "Classification with gpt-4o-2024-08-06 on piqa-sr_latn finished.\n",
      "gpt-3.5-turbo-0125\n",
      "Prediction finished. It took 1.0463015596071878 min for 100 instances - 0.6277809357643127 s per instance.\n",
      "Classification with gpt-3.5-turbo-0125 on piqa-sr_latn finished.\n",
      "piqa-bs\n",
      "gpt-4o-2024-08-06\n",
      "Prediction finished. It took 1.0069122751553854 min for 100 instances - 0.6041473650932312 s per instance.\n",
      "Classification with gpt-4o-2024-08-06 on piqa-bs finished.\n",
      "gpt-3.5-turbo-0125\n",
      "Prediction finished. It took 1.0784663438796998 min for 100 instances - 0.6470798063278198 s per instance.\n",
      "Classification with gpt-3.5-turbo-0125 on piqa-bs finished.\n",
      "piqa-sl-cer\n",
      "gpt-4o-2024-08-06\n",
      "Prediction finished. It took 1.2475922028223674 min for 100 instances - 0.7485553216934204 s per instance.\n",
      "Classification with gpt-4o-2024-08-06 on piqa-sl-cer finished.\n",
      "gpt-3.5-turbo-0125\n",
      "Prediction finished. It took 1.0572717706362407 min for 100 instances - 0.6343630623817443 s per instance.\n",
      "Classification with gpt-3.5-turbo-0125 on piqa-sl-cer finished.\n",
      "piqa-hr-ckm\n",
      "gpt-4o-2024-08-06\n",
      "Prediction finished. It took 1.213981827100118 min for 100 instances - 0.7283890962600708 s per instance.\n",
      "Classification with gpt-4o-2024-08-06 on piqa-hr-ckm finished.\n",
      "gpt-3.5-turbo-0125\n",
      "Prediction finished. It took 1.0819656332333882 min for 100 instances - 0.6491793799400329 s per instance.\n",
      "Classification with gpt-3.5-turbo-0125 on piqa-hr-ckm finished.\n"
     ]
    }
   ],
   "source": [
    "# First, evaluate the first two models, as GPT-5 takes much longer\n",
    "for test in tests[1:]:\n",
    "\tprint(test)\n",
    "\tfor model in [\"gpt-4o-2024-08-06\", \"gpt-3.5-turbo-0125\"]:\n",
    "\t\tprint(model)\n",
    "\t\tpredict_gpt(test, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "piqa-mk\n",
      "Prediction finished. It took 7.916777757803599 min for 100 instances - 4.7500666546821595 s per instance.\n",
      "Classification with gpt-5-2025-08-07 on piqa-mk finished.\n",
      "piqa-bg\n",
      "Prediction finished. It took 10.71853571732839 min for 100 instances - 6.431121430397034 s per instance.\n",
      "Classification with gpt-5-2025-08-07 on piqa-bg finished.\n",
      "piqa-sl\n",
      "Prediction finished. It took 12.195564572016398 min for 100 instances - 7.317338743209839 s per instance.\n",
      "Classification with gpt-5-2025-08-07 on piqa-sl finished.\n",
      "piqa-sr_cyrl\n",
      "Prediction finished. It took 13.426584800084433 min for 100 instances - 8.05595088005066 s per instance.\n",
      "Classification with gpt-5-2025-08-07 on piqa-sr_cyrl finished.\n",
      "piqa-hr\n",
      "Prediction finished. It took 8.12641879717509 min for 100 instances - 4.875851278305054 s per instance.\n",
      "Classification with gpt-5-2025-08-07 on piqa-hr finished.\n",
      "piqa-sr_latn\n",
      "Prediction finished. It took 11.984904567400614 min for 100 instances - 7.190942740440368 s per instance.\n",
      "Classification with gpt-5-2025-08-07 on piqa-sr_latn finished.\n",
      "piqa-bs\n",
      "Prediction finished. It took 7.173023287455241 min for 100 instances - 4.303813972473145 s per instance.\n",
      "Classification with gpt-5-2025-08-07 on piqa-bs finished.\n",
      "piqa-sl-cer\n",
      "Prediction finished. It took 30.173897270361582 min for 100 instances - 18.10433836221695 s per instance.\n",
      "Classification with gpt-5-2025-08-07 on piqa-sl-cer finished.\n",
      "piqa-hr-ckm\n",
      "Prediction finished. It took 39.04578589995702 min for 100 instances - 23.427471539974213 s per instance.\n",
      "Classification with gpt-5-2025-08-07 on piqa-hr-ckm finished.\n"
     ]
    }
   ],
   "source": [
    "# Add GPT-5\n",
    "for test in tests[1:]:\n",
    "\tprint(test)\n",
    "\tpredict_gpt(test, \"gpt-5-2025-08-07\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "emma_main",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
