
#### GB

| Model                                    | Test Dataset     | Language   |   Macro F1 |   Micro F1 |
|:-----------------------------------------|:-----------------|:-----------|-----------:|-----------:|
| gpt-4o-2024-08-06                        | ParlaCAP-EN-test | GB         |      0.745 |      0.744 |
| gpt-5                                    | ParlaCAP-EN-test | GB         |      0.734 |      0.732 |
| gpt-5-mini-2025-08-07                    | ParlaCAP-EN-test | GB         |      0.729 |      0.729 |
| ParlaCAP-classifier                      | ParlaCAP-EN-test | GB         |      0.723 |      0.724 |
| google/gemini-2.5-flash                  | ParlaCAP-EN-test | GB         |      0.709 |      0.712 |
| google/gemini-2.5-flash-lite             | ParlaCAP-EN-test | GB         |      0.679 |      0.683 |
| cohere/command-a                         | ParlaCAP-EN-test | GB         |      0.669 |      0.674 |
| mistralai/mistral-medium-3.1             | ParlaCAP-EN-test | GB         |      0.666 |      0.664 |
| gpt-5-nano-2025-08-07                    | ParlaCAP-EN-test | GB         |      0.657 |      0.664 |
| qwen3:32b                                | ParlaCAP-EN-test | GB         |      0.647 |      0.65  |
| gpt-4o-mini-2024-07-18                   | ParlaCAP-EN-test | GB         |      0.641 |      0.642 |
| llama3.3:latest                          | ParlaCAP-EN-test | GB         |      0.632 |      0.64  |
| mistralai/mistral-small-3.2-24b-instruct | ParlaCAP-EN-test | GB         |      0.629 |      0.624 |
| gemma3:27b                               | ParlaCAP-EN-test | GB         |      0.62  |      0.62  |
| gpt-3.5-turbo-0125                       | ParlaCAP-EN-test | GB         |      0.545 |      0.547 |
| llama4:scout                             | ParlaCAP-EN-test | GB         |      0.513 |      0.525 |
| deepseek-r1:14b                          | ParlaCAP-EN-test | GB         |      0.404 |      0.381 |
| dummy-stratified                         | ParlaCAP-EN-test | GB         |      0.049 |      0.056 |
| SVC                                      | ParlaCAP-EN-test | GB         |      0.035 |      0.071 |
| COMPLEMENTNB                             | ParlaCAP-EN-test | GB         |      0.008 |      0.045 |
| dummy-most_frequent                      | ParlaCAP-EN-test | GB         |      0.005 |      0.061 |

------------------------------------------

#### HR

| Model                                    | Test Dataset     | Language   |   Macro F1 |   Micro F1 |
|:-----------------------------------------|:-----------------|:-----------|-----------:|-----------:|
| gpt-5                                    | ParlaCAP-HR-test | HR         |      0.691 |      0.687 |
| gpt-5                                    | ParlaCAP-HR-test | HR         |      0.689 |      0.684 |
| ParlaCAP-classifier                      | ParlaCAP-HR-test | HR         |      0.686 |      0.677 |
| gpt-5-mini-2025-08-07                    | ParlaCAP-HR-test | HR         |      0.681 |      0.671 |
| gpt-5-mini-2025-08-07                    | ParlaCAP-HR-test | HR         |      0.678 |      0.672 |
| gpt-4o-2024-08-06                        | ParlaCAP-HR-test | HR         |      0.671 |      0.664 |
| google/gemini-2.5-flash                  | ParlaCAP-HR-test | HR         |      0.661 |      0.654 |
| mistralai/mistral-medium-3.1             | ParlaCAP-HR-test | HR         |      0.627 |      0.611 |
| gpt-5-nano-2025-08-07                    | ParlaCAP-HR-test | HR         |      0.606 |      0.598 |
| gpt-5-nano-2025-08-07                    | ParlaCAP-HR-test | HR         |      0.605 |      0.598 |
| google/gemini-2.5-flash-lite             | ParlaCAP-HR-test | HR         |      0.603 |      0.589 |
| qwen3:32b                                | ParlaCAP-HR-test | HR         |      0.598 |      0.581 |
| gpt-4o-mini-2024-07-18                   | ParlaCAP-HR-test | HR         |      0.59  |      0.588 |
| mistralai/mistral-small-3.2-24b-instruct | ParlaCAP-HR-test | HR         |      0.576 |      0.568 |
| gemma3:27b                               | ParlaCAP-HR-test | HR         |      0.555 |      0.551 |
| llama3.3:latest                          | ParlaCAP-HR-test | HR         |      0.555 |      0.565 |
| gpt-3.5-turbo-0125                       | ParlaCAP-HR-test | HR         |      0.487 |      0.484 |
| llama4:scout                             | ParlaCAP-HR-test | HR         |      0.484 |      0.484 |
| deepseek-r1:14b                          | ParlaCAP-HR-test | HR         |      0.311 |      0.284 |
| SVC                                      | ParlaCAP-HR-test | HR         |      0.073 |      0.125 |
| dummy-stratified                         | ParlaCAP-HR-test | HR         |      0.041 |      0.056 |
| COMPLEMENTNB                             | ParlaCAP-HR-test | HR         |      0.02  |      0.105 |
| dummy-most_frequent                      | ParlaCAP-HR-test | HR         |      0.006 |      0.067 |

------------------------------------------

#### BA

| Model                                    | Test Dataset     | Language   |   Macro F1 |   Micro F1 |
|:-----------------------------------------|:-----------------|:-----------|-----------:|-----------:|
| ParlaCAP-classifier                      | ParlaCAP-BA-test | BA         |      0.646 |      0.646 |
| gpt-5                                    | ParlaCAP-BA-test | BA         |      0.643 |      0.653 |
| gpt-4o-2024-08-06                        | ParlaCAP-BA-test | BA         |      0.629 |      0.63  |
| gpt-5-mini-2025-08-07                    | ParlaCAP-BA-test | BA         |      0.621 |      0.632 |
| google/gemini-2.5-flash                  | ParlaCAP-BA-test | BA         |      0.586 |      0.59  |
| gpt-5-nano-2025-08-07                    | ParlaCAP-BA-test | BA         |      0.564 |      0.585 |
| mistralai/mistral-small-3.2-24b-instruct | ParlaCAP-BA-test | BA         |      0.543 |      0.522 |
| llama3.3:latest                          | ParlaCAP-BA-test | BA         |      0.526 |      0.523 |
| gpt-4o-mini-2024-07-18                   | ParlaCAP-BA-test | BA         |      0.524 |      0.522 |
| google/gemini-2.5-flash-lite             | ParlaCAP-BA-test | BA         |      0.519 |      0.527 |
| mistralai/mistral-medium-3.1             | ParlaCAP-BA-test | BA         |      0.514 |      0.488 |
| gemma3:27b                               | ParlaCAP-BA-test | BA         |      0.51  |      0.5   |
| gpt-3.5-turbo-0125                       | ParlaCAP-BA-test | BA         |      0.489 |      0.488 |
| qwen3:32b                                | ParlaCAP-BA-test | BA         |      0.48  |      0.465 |
| llama4:scout                             | ParlaCAP-BA-test | BA         |      0.382 |      0.38  |
| deepseek-r1:14b                          | ParlaCAP-BA-test | BA         |      0.266 |      0.26  |
| SVC                                      | ParlaCAP-BA-test | BA         |      0.05  |      0.137 |
| dummy-stratified                         | ParlaCAP-BA-test | BA         |      0.042 |      0.061 |
| COMPLEMENTNB                             | ParlaCAP-BA-test | BA         |      0.02  |      0.136 |
| dummy-most_frequent                      | ParlaCAP-BA-test | BA         |      0.009 |      0.104 |

------------------------------------------

#### RS

| Model                                    | Test Dataset     | Language   |   Macro F1 |   Micro F1 |
|:-----------------------------------------|:-----------------|:-----------|-----------:|-----------:|
| gpt-5                                    | ParlaCAP-RS-test | RS         |      0.707 |      0.703 |
| ParlaCAP-classifier                      | ParlaCAP-RS-test | RS         |      0.707 |      0.705 |
| gpt-4o-2024-08-06                        | ParlaCAP-RS-test | RS         |      0.691 |      0.689 |
| gpt-5-mini-2025-08-07                    | ParlaCAP-RS-test | RS         |      0.684 |      0.677 |
| google/gemini-2.5-flash                  | ParlaCAP-RS-test | RS         |      0.633 |      0.632 |
| gpt-5-nano-2025-08-07                    | ParlaCAP-RS-test | RS         |      0.625 |      0.63  |
| google/gemini-2.5-flash-lite             | ParlaCAP-RS-test | RS         |      0.624 |      0.617 |
| llama3.3:latest                          | ParlaCAP-RS-test | RS         |      0.613 |      0.609 |
| mistralai/mistral-small-3.2-24b-instruct | ParlaCAP-RS-test | RS         |      0.601 |      0.595 |
| mistralai/mistral-medium-3.1             | ParlaCAP-RS-test | RS         |      0.597 |      0.578 |
| gpt-4o-mini-2024-07-18                   | ParlaCAP-RS-test | RS         |      0.593 |      0.588 |
| gemma3:27b                               | ParlaCAP-RS-test | RS         |      0.57  |      0.566 |
| qwen3:32b                                | ParlaCAP-RS-test | RS         |      0.569 |      0.551 |
| gpt-3.5-turbo-0125                       | ParlaCAP-RS-test | RS         |      0.554 |      0.541 |
| llama4:scout                             | ParlaCAP-RS-test | RS         |      0.478 |      0.471 |
| deepseek-r1:14b                          | ParlaCAP-RS-test | RS         |      0.303 |      0.279 |
| SVC                                      | ParlaCAP-RS-test | RS         |      0.057 |      0.125 |
| dummy-stratified                         | ParlaCAP-RS-test | RS         |      0.046 |      0.058 |
| COMPLEMENTNB                             | ParlaCAP-RS-test | RS         |      0.013 |      0.084 |
| dummy-most_frequent                      | ParlaCAP-RS-test | RS         |      0.006 |      0.066 |

------------------------------------------
