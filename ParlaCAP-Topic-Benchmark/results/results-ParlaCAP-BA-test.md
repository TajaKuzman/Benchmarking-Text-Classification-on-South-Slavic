## ParlaCAP-BA-test

| Model                                    | Test Dataset     |   Macro F1 |   Micro F1 |
|:-----------------------------------------|:-----------------|-----------:|-----------:|
| ParlaCAP-classifier                      | ParlaCAP-BA-test |      0.646 |      0.646 |
| gpt-5                                    | ParlaCAP-BA-test |      0.643 |      0.653 |
| gpt-4o-2024-08-06                        | ParlaCAP-BA-test |      0.629 |      0.63  |
| gpt-5-mini-2025-08-07                    | ParlaCAP-BA-test |      0.621 |      0.632 |
| google/gemini-2.5-flash                  | ParlaCAP-BA-test |      0.586 |      0.59  |
| gpt-5-nano-2025-08-07                    | ParlaCAP-BA-test |      0.564 |      0.585 |
| mistralai/mistral-small-3.2-24b-instruct | ParlaCAP-BA-test |      0.543 |      0.522 |
| llama3.3:latest                          | ParlaCAP-BA-test |      0.526 |      0.523 |
| gpt-4o-mini-2024-07-18                   | ParlaCAP-BA-test |      0.524 |      0.522 |
| google/gemini-2.5-flash-lite             | ParlaCAP-BA-test |      0.519 |      0.527 |
| mistralai/mistral-medium-3.1             | ParlaCAP-BA-test |      0.514 |      0.488 |
| gemma3:27b                               | ParlaCAP-BA-test |      0.51  |      0.5   |
| gpt-3.5-turbo-0125                       | ParlaCAP-BA-test |      0.489 |      0.488 |
| qwen3:32b                                | ParlaCAP-BA-test |      0.48  |      0.465 |
| llama4:scout                             | ParlaCAP-BA-test |      0.382 |      0.38  |
| deepseek-r1:14b                          | ParlaCAP-BA-test |      0.266 |      0.26  |
| SVC                                      | ParlaCAP-BA-test |      0.05  |      0.137 |
| dummy-stratified                         | ParlaCAP-BA-test |      0.042 |      0.061 |
| COMPLEMENTNB                             | ParlaCAP-BA-test |      0.02  |      0.136 |
| dummy-most_frequent                      | ParlaCAP-BA-test |      0.009 |      0.104 |