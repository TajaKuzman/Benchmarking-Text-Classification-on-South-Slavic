{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tajak/miniconda3/envs/conda_emma/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(440, 9) (869, 9)\n"
     ]
    }
   ],
   "source": [
    "# Load the test datasets\n",
    "\n",
    "test_en = pd.read_json(\"../../datasets/ParlaCAP-EN-test/ParlaMint-EN-CAP-test-dataset.jsonl\", lines=True)\n",
    "test_hr = pd.read_json(\"../../datasets/ParlaCAP-HR-test/ParlaMint-HR-CAP-test-dataset.jsonl\", lines=True)\n",
    "\n",
    "print(test_en.shape, test_hr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(29779, 13)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Text_ID</th>\n",
       "      <th>text</th>\n",
       "      <th>Date</th>\n",
       "      <th>Speaker_role</th>\n",
       "      <th>Speaker_name</th>\n",
       "      <th>length</th>\n",
       "      <th>lang</th>\n",
       "      <th>labels</th>\n",
       "      <th>split</th>\n",
       "      <th>eval</th>\n",
       "      <th>keyword</th>\n",
       "      <th>public-lands-candidate-instance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ParlaMint-ES-PV_2019-11-15.u95</td>\n",
       "      <td>ParlaMint-ES-PV_2019-11-15</td>\n",
       "      <td>Sailburu anderea, prozesu guztia esplikatu did...</td>\n",
       "      <td>2019-11-15</td>\n",
       "      <td>Regular</td>\n",
       "      <td>Ubera Aranzeta, Rebeka</td>\n",
       "      <td>227</td>\n",
       "      <td>ES-PV</td>\n",
       "      <td>Education</td>\n",
       "      <td>train</td>\n",
       "      <td>no</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ParlaMint-AT_2005-12-06-022-XXII-NRSITZ-00129_...</td>\n",
       "      <td>ParlaMint-AT_2005-12-06-022-XXII-NRSITZ-00129</td>\n",
       "      <td>Herr Präsident! Frau Bundesministerin! Sehr ge...</td>\n",
       "      <td>2005-12-06</td>\n",
       "      <td>Regular</td>\n",
       "      <td>Praßl, Michael</td>\n",
       "      <td>222</td>\n",
       "      <td>AT</td>\n",
       "      <td>Technology</td>\n",
       "      <td>train</td>\n",
       "      <td>no</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  ID  \\\n",
       "0                     ParlaMint-ES-PV_2019-11-15.u95   \n",
       "1  ParlaMint-AT_2005-12-06-022-XXII-NRSITZ-00129_...   \n",
       "\n",
       "                                         Text_ID  \\\n",
       "0                     ParlaMint-ES-PV_2019-11-15   \n",
       "1  ParlaMint-AT_2005-12-06-022-XXII-NRSITZ-00129   \n",
       "\n",
       "                                                text       Date Speaker_role  \\\n",
       "0  Sailburu anderea, prozesu guztia esplikatu did... 2019-11-15      Regular   \n",
       "1  Herr Präsident! Frau Bundesministerin! Sehr ge... 2005-12-06      Regular   \n",
       "\n",
       "             Speaker_name  length   lang      labels  split eval keyword  \\\n",
       "0  Ubera Aranzeta, Rebeka     227  ES-PV   Education  train   no    None   \n",
       "1          Praßl, Michael     222     AT  Technology  train   no    None   \n",
       "\n",
       "  public-lands-candidate-instance  \n",
       "0                            None  \n",
       "1                            None  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the training dataset\n",
    "\n",
    "train_df = pd.read_json(\"../../datasets/ParlaCAP-train/ParlaCAP-train.jsonl\", lines=True)\n",
    "\n",
    "print(train_df.shape)\n",
    "\n",
    "train_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dummy(train_df, test_df, test_df_name):\n",
    "    # Create X_train and Y_train parts, used for sci kit learning\n",
    "    # List of texts in training split\n",
    "    X_train = list(train_df.text)\n",
    "    # List of labels in training split\n",
    "    Y_train = list(train_df.labels)\n",
    "\n",
    "    # List of texts in test split\n",
    "    X_test = list(test_df.text)\n",
    "    # List of labels in test split\n",
    "    Y_test = list(test_df.labels)\n",
    "\n",
    "    print(len(X_train), len(Y_train), len(X_test), len(Y_test))\n",
    "\n",
    "    # Create a list of labels\n",
    "    labels = list(test_df.labels.unique())\n",
    "    print(\"Labels: {}\".format(labels))\n",
    "\n",
    "    for strategy in [\"stratified\", \"most_frequent\"]:\n",
    "        model = f\"dummy-{strategy}\"\n",
    "\n",
    "        dummy_mf = DummyClassifier(strategy=strategy)\n",
    "\n",
    "        # Train the model\n",
    "        dummy_mf.fit(X_train, Y_train)\n",
    "\n",
    "        #Get the predictions\n",
    "        y_pred_mf = dummy_mf.predict(X_test)\n",
    "\n",
    "        y_pred = list(y_pred_mf)\n",
    "\n",
    "        # Create a json with results\n",
    "        current_results = {\n",
    "            \"system\": model,\n",
    "            \"predictions\": [\n",
    "                {\n",
    "                \"train\": \"ParlaCAP-train\",\n",
    "                \"test\": \"{}\".format(test_df_name),\n",
    "                \"predictions\": y_pred,\n",
    "                }\n",
    "            ],\n",
    "            #\"model\": model_type_dict[model][1],\n",
    "            #\"args\": model_args,\n",
    "            }\n",
    "\n",
    "        # Save the results as a new json\n",
    "        with open(\"submissions/submission-{}-{}.json\".format(model, test_df_name), \"w\") as file:\n",
    "            json.dump(current_results, file)\n",
    "\n",
    "        print(\"Classification with {} on {} finished.\".format(model, test_df_name))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29779 29779 869 869\n",
      "Labels: ['Government Operations', 'Defense', 'Environment', 'Culture', 'Law and Crime', 'Education', 'Labor', 'Transportation', 'Domestic Commerce', 'Macroeconomics', 'Health', 'International Affairs', 'Other', 'Civil Rights', 'Immigration', 'Agriculture', 'Energy', 'Housing', 'Foreign Trade', 'Social Welfare', 'Public Lands', 'Technology']\n",
      "Classification with dummy-stratified on ParlaCAP-HR-test finished.\n",
      "Classification with dummy-most_frequent on ParlaCAP-HR-test finished.\n"
     ]
    }
   ],
   "source": [
    "dummy(train_df, test_hr, \"ParlaCAP-HR-test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29779 29779 440 440\n",
      "Labels: ['Government Operations', 'Foreign Trade', 'Energy', 'Social Welfare', 'Defense', 'Environment', 'Culture', 'Labor', 'Transportation', 'Civil Rights', 'International Affairs', 'Other', 'Health', 'Domestic Commerce', 'Housing', 'Agriculture', 'Education', 'Macroeconomics', 'Law and Crime', 'Technology', 'Immigration', 'Public Lands']\n",
      "Classification with dummy-stratified on ParlaCAP-EN-test finished.\n",
      "Classification with dummy-most_frequent on ParlaCAP-EN-test finished.\n"
     ]
    }
   ],
   "source": [
    "dummy(train_df, test_en, \"ParlaCAP-EN-test\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_emma",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
