{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
      "env: CUDA_VISIBLE_DEVICES=7\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
    "%env CUDA_VISIBLE_DEVICES=7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tajak/miniconda3/envs/conda_emma/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "import sys\n",
    "import json\n",
    "from scipy.special import softmax\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "from simpletransformers.classification import ClassificationModel, ClassificationArgs\n",
    "from transformers import AutoModelForSequenceClassification, TextClassificationPipeline, AutoTokenizer, AutoConfig\n",
    "import torch\n",
    "import argparse\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2600, 14) (2600, 14)\n"
     ]
    }
   ],
   "source": [
    "# Load the test datasets\n",
    "\n",
    "test_en = pd.read_json(\"../../datasets/ParlaSent-EN-test/ParlaSent_EN_test.jsonl\", lines=True)\n",
    "test_bcs = pd.read_json(\"../../datasets/ParlaSent-BSC-test/ParlaSent_BCS_test.jsonl\", lines=True)\n",
    "\n",
    "print(test_en.shape, test_bcs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_3_category_label(x: float) -> str:\n",
    "    import numpy as np\n",
    "    three_category_mapper = {\n",
    "        0: 'Negative',\n",
    "        1: 'Neutral',\n",
    "        2: 'Positive',\n",
    "    }\n",
    "    return three_category_mapper[\n",
    "      int(np.clip(np.round(x), 0, 5) // 2)\n",
    "      ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_sentiment(df_test_name):\n",
    "\tdfs = {\n",
    "\t\t\"ParlaSent-EN-test\": test_en,\n",
    "\t\t\"ParlaSent-BCS-test\": test_bcs\n",
    "\t}\n",
    "\n",
    "\tdf = dfs[df_test_name]\n",
    "\ttexts = df[\"text\"].to_list()\n",
    "\n",
    "\tMODEL = \"classla/xlm-r-parlasent\"\n",
    "\ttokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
    "\tmodel = AutoModelForSequenceClassification.from_pretrained(MODEL)\n",
    "\n",
    "\tpipe = TextClassificationPipeline(model=model, tokenizer=tokenizer, return_all_scores=True,task='sentiment_analysis', device=0, function_to_apply=\"none\")\n",
    "\t\n",
    "\toutput_list = pipe(texts)\n",
    "\n",
    "\tlabel_list = []\n",
    "\n",
    "\tfor x in output_list:\n",
    "\t\tlabel_list.append(x[0][\"score\"])\n",
    "\n",
    "\t# transform the float values to the 3 concrete sentiment labels\n",
    "\tprediction_list = [get_3_category_label(x) for x in label_list]\n",
    "\t\n",
    "\t# Create a json with results\n",
    "\n",
    "\tcurrent_results = {\n",
    "\t\t\"system\": \"XLM-R-ParlaSent\",\n",
    "\t\t\"predictions\": [\n",
    "\t\t\t{\n",
    "\t\t\t\"train\": \"ParlaSent\",\n",
    "\t\t\t\"test\": \"{}\".format(df_test_name),\n",
    "\t\t\t\"predictions\": prediction_list,\n",
    "\t\t\t}\n",
    "\t\t]\n",
    "\t\t}\n",
    "\n",
    "\t# Save the results as a new json\n",
    "\twith open(\"submissions/submission-{}-{}.json\".format(\"XLM-R-ParlaSent\", df_test_name), \"w\") as file:\n",
    "\t\tjson.dump(current_results, file)\n",
    "\n",
    "\tprint(\"Classification with {} on {} finished.\".format(\"XLM-R-ParlaSent\", df_test_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification with XLM-R-ParlaSent on ParlaSent-EN-test finished.\n"
     ]
    }
   ],
   "source": [
    "predict_sentiment(\"ParlaSent-EN-test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification with XLM-R-ParlaSent on ParlaSent-BCS-test finished.\n"
     ]
    }
   ],
   "source": [
    "predict_sentiment(\"ParlaSent-BCS-test\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_emma",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
