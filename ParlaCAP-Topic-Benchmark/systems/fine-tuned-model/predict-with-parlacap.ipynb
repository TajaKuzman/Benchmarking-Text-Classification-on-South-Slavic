{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
      "env: CUDA_VISIBLE_DEVICES=4\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
    "%env CUDA_VISIBLE_DEVICES=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tajak/miniconda3/envs/conda_emma/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "import sys\n",
    "import json\n",
    "from scipy.special import softmax\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "from simpletransformers.classification import ClassificationModel, ClassificationArgs\n",
    "from transformers import AutoModelForSequenceClassification, TextClassificationPipeline, AutoTokenizer, AutoConfig\n",
    "import torch\n",
    "import argparse\n",
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(440, 9) (869, 9)\n"
     ]
    }
   ],
   "source": [
    "# Load the test datasets\n",
    "\n",
    "test_en = pd.read_json(\"../../datasets/ParlaCAP-EN-test/ParlaMint-EN-CAP-test-dataset.jsonl\", lines=True)\n",
    "test_hr = pd.read_json(\"../../datasets/ParlaCAP-HR-test/ParlaMint-HR-CAP-test-dataset.jsonl\", lines=True)\n",
    "\n",
    "print(test_en.shape, test_hr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_classifier(test_df, df_test_name):\n",
    "\tprint(\"Loading the model ...\")\n",
    "\n",
    "\tcap_model = AutoModelForSequenceClassification.from_pretrained(\"classla/ParlaCAP-Topic-Classifier\")\n",
    "\tcap_model.to(\"cuda:0\")\n",
    "\n",
    "\tcap_tokenizer = AutoTokenizer.from_pretrained(\"classla/ParlaCAP-Topic-Classifier\")\n",
    "\tprint(\"Model loaded.\")\n",
    "\n",
    "\tcap_labels = [\"Education\", \"Technology\", \"Health\", \"Environment\", \"Housing\", \"Labor\", \"Defense\", \"Government Operations\", \"Social Welfare\", \"Other\", \"Macroeconomics\", \"Domestic Commerce\", \"Civil Rights\", \"International Affairs\", \"Transportation\", \"Immigration\", \"Law and Crime\", \"Agriculture\", \"Foreign Trade\", \"Culture\", \"Public Lands\", \"Energy\"]\n",
    "\n",
    "\n",
    "\t# Improved code to optimize inference speed\n",
    "\tdef transcode(logit, cap_labels):\n",
    "\t\tlogit = softmax(logit)\n",
    "\t\tmax_idx = np.argmax(logit)\n",
    "\t\tif logit[max_idx] >= 0.6:\n",
    "\t\t\tlabel =  cap_labels[max_idx]\n",
    "\t\t# If classifier's confidence is lower, output label \"Mix\"\n",
    "\t\telse:\n",
    "\t\t\tlabel = 'Mix'\n",
    "\t\tsorted_labels = sorted([(cap_labels[i], logit[i]) for i in np.where(logit > 0)[0]], key=lambda x: -x[1])\n",
    "\t\treturn [label, sorted_labels]\n",
    "\n",
    "\ttexts = test_df[\"text\"].to_list()\n",
    "\tpreds = []\n",
    "\n",
    "\tprint(\"Prediction started.\")\n",
    "\n",
    "\t# If there is CUDA out of memory issue, make the batch size smaller.\n",
    "\tbatch_size = 600\n",
    "\n",
    "\t# split the list into batch sizes\n",
    "\tdef split_into_batches(lst, batch_size=600):\n",
    "\t\treturn [lst[i:i + batch_size] for i in range(0, len(lst), batch_size)]\n",
    "\t\n",
    "\tbatches = split_into_batches(texts)\n",
    "\n",
    "\tfor batch in batches:\n",
    "\t\tinputs = cap_tokenizer(batch, max_length=512, truncation=True, padding=True, return_tensors=\"pt\").to(\"cuda:0\")\n",
    "\t\twith torch.no_grad():\n",
    "\t\t\tlogits = cap_model(**inputs).logits\n",
    "\t\tfor idx in range(len(logits)):\n",
    "\t\t\tcurrent_logit = logits[idx].tolist()\n",
    "\t\t\tresults = transcode(current_logit, cap_labels)\n",
    "\t\t\tcurrent_cap = results[0]\n",
    "\t\t\tpreds.append(current_cap)\n",
    "\t\n",
    "\t# Create a json with results\n",
    "\n",
    "\tcurrent_results = {\n",
    "\t\t\"system\": \"ParlaCAP-classifier\",\n",
    "\t\t\"predictions\": [\n",
    "\t\t\t{\n",
    "\t\t\t\"train\": \"ParlaCAP-train\",\n",
    "\t\t\t\"test\": \"{}\".format(df_test_name),\n",
    "\t\t\t\"predictions\": preds,\n",
    "\t\t\t}\n",
    "\t\t]\n",
    "\t\t}\n",
    "\n",
    "\t# Save the results as a new json\n",
    "\twith open(\"submissions/submission-{}-{}.json\".format(\"ParlaCAP\", df_test_name), \"w\") as file:\n",
    "\t\tjson.dump(current_results, file)\n",
    "\n",
    "\tprint(\"Classification with {} on {} finished.\".format(\"ParlaCAP\", df_test_name))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the model ...\n",
      "Model loaded.\n",
      "Prediction started.\n",
      "Classification with ParlaCAP on ParlaCAP-EN-test finished.\n"
     ]
    }
   ],
   "source": [
    "apply_classifier(test_en, \"ParlaCAP-EN-test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the model ...\n",
      "Model loaded.\n",
      "Prediction started.\n",
      "Classification with ParlaCAP on ParlaCAP-HR-test finished.\n"
     ]
    }
   ],
   "source": [
    "apply_classifier(test_hr, \"ParlaCAP-HR-test\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_emma",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
